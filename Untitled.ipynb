{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c848767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1252faed03d96b9f\n",
      "Found cached dataset json (/home/korn/.cache/huggingface/datasets/json/default-1252faed03d96b9f/0.0.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8c3115092444e491443e1cea7ef725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = DatasetDict.from_json(\n",
    "    {\n",
    "#         \"train\": \"oad/train.json\",\n",
    "        \"test\": \"oad/test.json\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f0ca7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['p1', 'p2', 'post_id1', 'post_id2', 'label'],\n",
       "        num_rows: 2309374\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['p1', 'p2', 'post_id1', 'post_id2', 'label'],\n",
       "        num_rows: 531928\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c92067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8838eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate.load(\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e311a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = metrics.compute(prediction_scores = [1,0,0,1], references=[1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f75afc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('d', 0.2)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'d':0.2}.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91557faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8333333333333333, 'd': 0.2}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(d.items()) + list({'d': 0.2}.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6325b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Convert the dictionary-like variable into a DataFrame\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Split positive and negative samples\n",
    "positive_samples = df[df['label'] == 1]\n",
    "negative_samples = df[df['label'] == 0]\n",
    "\n",
    "# Split positive and negative samples into training and validation sets\n",
    "positive_train, positive_val = train_test_split(positive_samples, test_size=0.05, random_state=42)\n",
    "negative_train, negative_val = train_test_split(negative_samples, test_size=0.05, random_state=42)\n",
    "\n",
    "# Combine positive and negative splits to create training and validation sets\n",
    "train_data = pd.concat([positive_train, negative_train])\n",
    "val_data = pd.concat([positive_val, negative_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "863ec300",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = DatasetDict(\n",
    "        {\n",
    "            \"train\": Dataset.from_pandas(train_data).remove_columns(['__index_level_0__']),\n",
    "            \"validation\": Dataset.from_pandas(val_data).remove_columns(['__index_level_0__']),\n",
    "            \"test\": dataset[\"test\"]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc52f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(dataset[\"train\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6cfc075",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_dict() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_945971/1167225379.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a new Dataset for each split with custom attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m new_splits = {\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: from_dict() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "# Create a new Dataset for each split with custom attributes\n",
    "new_splits = {\n",
    "    \"train\": Dataset.from_dict(train_data),\n",
    "    \"validation\": Dataset.from_dict(val_data),\n",
    "    \"test\": dataset[\"test\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "952c8d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p1', 'p2', 'label'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01daf7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['p1', 'p2', 'label'],\n",
       "        num_rows: 1999728\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['p1', 'p2', 'label'],\n",
       "        num_rows: 105250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['p1', 'p2', 'label'],\n",
       "        num_rows: 483654\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
